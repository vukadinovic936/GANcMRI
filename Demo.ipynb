{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da85e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from ipywidgets import interactive, FloatSlider, Button, VBox\n",
    "from IPython.display import display as ipython_display\n",
    "from tqdm import tqdm\n",
    "#local\n",
    "import dnnlib\n",
    "from dnnlib import tflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c020c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'best_net.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ec7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define load model functions\n",
    "_cached_networks = dict()\n",
    "def load_networks(path):\n",
    "    if path in _cached_networks:\n",
    "        return _cached_networks[path]\n",
    "    stream = open(path, 'rb')\n",
    "    tflib.init_tf()\n",
    "    with stream:\n",
    "        G, D, Gs = pickle.load(stream, encoding='latin1')\n",
    "    _cached_networks[path] = G, D, Gs\n",
    "    return G, D, Gs\n",
    "# Code to load the StyleGAN2 Model\n",
    "def load_model():\n",
    "    _G, _D, Gs = load_networks(model_path)\n",
    "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
    "    Gs_kwargs = dnnlib.EasyDict()\n",
    "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "    Gs_kwargs.randomize_noise = False\n",
    "    return Gs, noise_vars, Gs_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define helper functions\n",
    "def get_control_latent_vectors(path):\n",
    "    files = [x for x in Path(path).iterdir() if str(x).endswith('.npy')]\n",
    "    latent_vectors = {f.name[:-4]:np.load(f) for f in files}\n",
    "    return latent_vectors\n",
    "#load latent directions\n",
    "latent_controls = get_control_latent_vectors('trajectories/')\n",
    "\n",
    "def generate_image_from_projected_latents(latent_vector):\n",
    "    images = Gs.components.synthesis.run(latent_vector, **Gs_kwargs)\n",
    "    return images\n",
    "\n",
    "def create_video(image):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.close()\n",
    "    def animator(N): # N is the animation frame number\n",
    "        ax.imshow(image[N],cmap='gray')\n",
    "        ax.axis('off')\n",
    "        return ax\n",
    "    PlotFrames = range(0,image.shape[0],1)\n",
    "    anim = animation.FuncAnimation(fig,animator,frames=PlotFrames,interval=50)\n",
    "    rc('animation', html='jshtml') # embed in the HTML for Google Colab\n",
    "    return anim\n",
    "\n",
    "def create_videos(image1, image2):\n",
    "    assert image1.shape[0] == image2.shape[0], \"Both videos should have the same number of frames\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)  # 1 row, 2 columns\n",
    "    plt.close()\n",
    "    \n",
    "    def animator(N): \n",
    "        # Clear previous frames\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        \n",
    "        ax1.set_title(\"ED-to-ES\")\n",
    "        ax2.set_title(\"Frame-to-frame\")\n",
    "        \n",
    "        ax1.imshow(image1[N], cmap='gray')\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(image2[N], cmap='gray')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        return ax1, ax2\n",
    "    \n",
    "    # Assuming both videos have the same length\n",
    "    PlotFrames = range(0, image1.shape[0], 1)\n",
    "    anim = animation.FuncAnimation(fig, animator, frames=PlotFrames, interval=50)  # adjusted interval to 50ms\n",
    "    rc('animation', html='jshtml') # embed in the HTML for Google Colab\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define video generation methods\n",
    "def ED_to_ES(latent_code):\n",
    "    all_imgs = []\n",
    "    amounts_up = [i/25 for i in range(0,25)]\n",
    "    amounts_down = [1-i/25 for i in range(1,26)]\n",
    "\n",
    "    for amount_to_move in tqdm(amounts_up):\n",
    "        modified_latent_code = latent_code + latent_controls[\"time\"]*amount_to_move\n",
    "        images = generate_image_from_projected_latents(modified_latent_code)\n",
    "        all_imgs.append(np.array(images[0]))\n",
    "\n",
    "    for amount_to_move in tqdm(amounts_down):\n",
    "        modified_latent_code = latent_code + latent_controls[\"time\"]*amount_to_move\n",
    "        images = generate_image_from_projected_latents(modified_latent_code)\n",
    "        all_imgs.append(np.array(images[0]))\n",
    "    \n",
    "    return np.array(all_imgs)\n",
    "\n",
    "def frame_to_frame(latent_code):\n",
    "    modified_latent_code = np.copy(latent_code)\n",
    "    full_video = [generate_image_from_projected_latents(modified_latent_code)]\n",
    "    for i in tqdm(range(49)):\n",
    "        modified_latent_code = modified_latent_code +  latent_controls[f'{i}{i+1}']\n",
    "        ims = generate_image_from_projected_latents(modified_latent_code)\n",
    "        full_video.append(ims)\n",
    "    return np.array(full_video).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa20e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "Gs, noise_vars, Gs_kwargs = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177eef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a random latent code\n",
    "rnd = np.random.RandomState(3)\n",
    "z = rnd.randn(1, *Gs.input_shape[1:])\n",
    "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
    "tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars})\n",
    "random_img_latent_code = Gs.components.mapping.run(z,None)\n",
    "\n",
    "#make it be ED frame\n",
    "random_img_latent_code -= 0.7*latent_controls['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_display_videos(sphericity_index=0.0, lv_area=0.0):\n",
    "    #apply physiological adjustment\n",
    "    adjusted_latent_code = np.copy(random_img_latent_code)\n",
    "    adjusted_latent_code += sphericity_index * latent_controls['sphericity_index']\n",
    "    adjusted_latent_code += lv_area * latent_controls['lv_area']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)  # 1 row, 2 columns\n",
    "    \n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    \n",
    "    img = generate_image_from_projected_latents(adjusted_latent_code).squeeze()\n",
    "    ax1.set_title(\"ED-to-ES\")\n",
    "    ax2.set_title(\"Frame-to-frame\")\n",
    "\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(img, cmap='gray')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def on_generate_videos_button_click(button):\n",
    "    # Access the current values of the sliders\n",
    "    sphericity_index = sphericity_index_slider.value\n",
    "    lv_area = lv_area_slider.value\n",
    "\n",
    "    # Apply physiological adjustment\n",
    "    adjusted_latent_code = np.copy(random_img_latent_code)\n",
    "    adjusted_latent_code += sphericity_index * latent_controls['sphericity_index']\n",
    "    adjusted_latent_code += lv_area * latent_controls['lv_area']\n",
    "\n",
    "    # Generate videos\n",
    "    ED_to_ES_video = ED_to_ES(adjusted_latent_code)\n",
    "    frame_to_frame_video = frame_to_frame(adjusted_latent_code)\n",
    "    anim = create_videos(ED_to_ES_video, frame_to_frame_video)\n",
    "    ipython_display(anim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_videos_button = Button(description=\"Generate Videos\")\n",
    "generate_videos_button.on_click(on_generate_videos_button_click)\n",
    "\n",
    "sphericity_index_slider = FloatSlider(min=-2, max=3, step=0.1, value=0.0, description='Sphericity:')\n",
    "lv_area_slider = FloatSlider(min=-2, max=3, step=0.1, value=0.0, description='LV Area:')\n",
    "\n",
    "# Display the interactive interface\n",
    "interactive_plot = interactive(create_and_display_videos, sphericity_index=sphericity_index_slider, lv_area=lv_area_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '200px'  \n",
    "display(VBox([interactive_plot, generate_videos_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d879f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
